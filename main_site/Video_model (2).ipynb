{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Video_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vN-EKTQlKf5H"
      },
      "source": [
        "First I have to use google drive to get the dataset in since it is ~6.5gb which is too much for colab\n",
        "Source: https://www.freecodecamp.org/news/how-to-transfer-large-files-to-google-colab-and-remote-jupyter-notebooks-26ca252892fa/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "md3JBcUO3LH_",
        "outputId": "42515661-5966-4ce6-9fcc-d3675a2e4302"
      },
      "source": [
        "!pip install PyDrive"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: PyDrive in /usr/local/lib/python3.7/dist-packages (1.3.1)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from PyDrive) (4.1.3)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.7/dist-packages (from PyDrive) (3.13)\n",
            "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.7/dist-packages (from PyDrive) (1.12.8)\n",
            "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from oauth2client>=4.0.0->PyDrive) (1.15.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.2.8)\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.17.4)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.4.8)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from oauth2client>=4.0.0->PyDrive) (4.7.2)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (3.0.1)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.26.2)\n",
            "Requirement already satisfied: google-auth>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.28.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.0.4)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2.23.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (1.53.0)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (54.2.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (20.9)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2018.9)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (3.12.4)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.2->PyDrive) (4.2.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (1.24.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BsGr3EN3NKn"
      },
      "source": [
        "from google.colab import drive"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTRlgC8m3Oka",
        "outputId": "59f9a604-896f-42b0-8e12-cedc06810efc"
      },
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJQOUqzfJ9R8",
        "outputId": "974f0629-8156-4e03-bca9-5c65179b1572"
      },
      "source": [
        "!ls '/content/gdrive/MyDrive'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 111incl2_2020.gdoc\t\t\t      'outline for formal report.gdoc'\n",
            " 111incl2_2020.pdf\t\t\t       UCF101.rar\n",
            "'Chair concepts.gdoc'\t\t\t      'Untitled document (1).gdoc'\n",
            "'Colab Notebooks'\t\t\t      'Untitled document (2).gdoc'\n",
            "'Copy of P-11 Poster Layout.gslides'\t      'Untitled document.gdoc'\n",
            "'Experiment 1 Shovel or Claw.gdoc'\t      'Untitled spreadsheet.gsheet'\n",
            "'Getting started.pdf'\t\t\t      'WDM of Claw.gsheet'\n",
            "'Google doc'\t\t\t\t       WilliamLaurence.docx\n",
            "'Module 2 Presentation.gslides'\t\t       WilliamReading.docx\n",
            "'Module 2 Presentation - Pie chart 1.gsheet'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILripyvqZDVt"
      },
      "source": [
        "For reference, this next step took me about 8 minutes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dY7KJTsHXDUT",
        "outputId": "3ccb4038-bcca-45cd-b657-a4a0ac48f2c0"
      },
      "source": [
        "!pip install pyunpack\n",
        "!pip install patool\n",
        "from pyunpack import Archive\n",
        "Archive('/content/gdrive/MyDrive/UCF101.rar').extractall('/content')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyunpack\n",
            "  Downloading https://files.pythonhosted.org/packages/83/29/020436b1d8e96e5f26fa282b9c3c13a3b456a36b9ea2edc87c5fed008369/pyunpack-0.2.2-py2.py3-none-any.whl\n",
            "Collecting easyprocess\n",
            "  Downloading https://files.pythonhosted.org/packages/48/3c/75573613641c90c6d094059ac28adb748560d99bd27ee6f80cce398f404e/EasyProcess-0.3-py2.py3-none-any.whl\n",
            "Collecting entrypoint2\n",
            "  Downloading https://files.pythonhosted.org/packages/8a/b0/8ef4b1d8be02448d164c52466530059d7f57218655d21309a0c4236d7454/entrypoint2-0.2.4-py3-none-any.whl\n",
            "Installing collected packages: easyprocess, entrypoint2, pyunpack\n",
            "Successfully installed easyprocess-0.3 entrypoint2-0.2.4 pyunpack-0.2.2\n",
            "Collecting patool\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/94/52243ddff508780dd2d8110964320ab4851134a55ab102285b46e740f76a/patool-1.12-py2.py3-none-any.whl (77kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 7.3MB/s \n",
            "\u001b[?25hInstalling collected packages: patool\n",
            "Successfully installed patool-1.12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FelIjOO9LNjD"
      },
      "source": [
        "Everything after this point is based off this source:\n",
        "https://www.analyticsvidhya.com/blog/2019/09/step-by-step-deep-learning-tutorial-video-classification-python/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-SGPdt_K2l1"
      },
      "source": [
        "Now i'm setting up the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXni0THTKoEU"
      },
      "source": [
        "import cv2     # for capturing videos\n",
        "import math   # for mathematical operations\n",
        "import matplotlib.pyplot as plt    # for plotting the images\n",
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "from keras.preprocessing import image   # for preprocessing the images\n",
        "import numpy as np    # for mathematical operations\n",
        "from keras.utils import np_utils\n",
        "from skimage.transform import resize   # for resizing images\n",
        "from sklearn.model_selection import train_test_split\n",
        "from glob import glob\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "wOjjVLSiK11o",
        "outputId": "5ee1ba2b-bc3c-4d40-edbd-fdf72dda6787"
      },
      "source": [
        "# open the .txt file which have names of training videos\n",
        "f = open(\"/content/trainlist01.txt\", \"r\")\n",
        "temp = f.read()\n",
        "videos = temp.split('\\n')\n",
        "\n",
        "# creating a dataframe having video names\n",
        "train = pd.DataFrame()\n",
        "train['video_name'] = videos\n",
        "train = train[:-1]\n",
        "train.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>video_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c01.avi 1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c02.avi 1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c03.avi 1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c04.avi 1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c05.avi 1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      video_name\n",
              "0  ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c01.avi 1\n",
              "1  ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c02.avi 1\n",
              "2  ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c03.avi 1\n",
              "3  ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c04.avi 1\n",
              "4  ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c05.avi 1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "sy7xpeCmK9Pi",
        "outputId": "ec1461ed-5a8f-4dbf-9d6c-e59568bc106c"
      },
      "source": [
        "# open the .txt file which have names of test videos\n",
        "f = open(\"/content/testlist01.txt\", \"r\")\n",
        "temp = f.read()\n",
        "videos = temp.split('\\n')\n",
        "\n",
        "# creating a dataframe having video names\n",
        "test = pd.DataFrame()\n",
        "test['video_name'] = videos\n",
        "test = test[:-1]\n",
        "test.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>video_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c01.avi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c02.avi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c03.avi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c04.avi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c05.avi</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    video_name\n",
              "0  ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c01.avi\n",
              "1  ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c02.avi\n",
              "2  ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c03.avi\n",
              "3  ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c04.avi\n",
              "4  ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c05.avi"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yeky_AbLGdq"
      },
      "source": [
        "# creating tags for training videos\n",
        "train_video_tag = []\n",
        "for i in range(train.shape[0]):\n",
        "    train_video_tag.append(train['video_name'][i].split('/')[0])\n",
        "    \n",
        "train['tag'] = train_video_tag\n",
        "\n",
        "# creating tags for test videos\n",
        "test_video_tag = []\n",
        "for i in range(test.shape[0]):\n",
        "    test_video_tag.append(test['video_name'][i].split('/')[0])\n",
        "    \n",
        "test['tag'] = test_video_tag"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B48_BzCMaqjy",
        "outputId": "cb7b3a83-266d-4af7-91bc-0a69a38302f1"
      },
      "source": [
        "# storing the frames from training videos\n",
        "for i in tqdm(range(train.shape[0])):\n",
        "    count = 0\n",
        "    videoFile = train['video_name'][i]\n",
        "    cap = cv2.VideoCapture('/content/UCF-101/'+videoFile.split(' ')[0])   # capturing the video from the given path\n",
        "\n",
        "    frameRate = cap.get(5) #frame rate\n",
        "    x=1\n",
        "\n",
        "    while(cap.isOpened()):\n",
        "     \n",
        "        frameId = cap.get(1) #current frame number\n",
        "        ret, frame = cap.read()\n",
        "        if (ret != True):\n",
        "            break\n",
        "        if (frameId % math.floor(frameRate) == 0):\n",
        "            # storing the frames in a new folder named train_1\n",
        "            filename ='/train_1/' + videoFile.split('/')[1].split(' ')[0] +\"_frame%d.jpg\" % count;count+=1\n",
        "            cv2.imwrite(filename, frame)\n",
        "    cap.release()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 9537/9537 [10:20<00:00, 15.37it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4-C5LS9LRu7",
        "outputId": "2dd09b5c-97be-41d9-9a5e-bddef0584fff"
      },
      "source": [
        "# getting the names of all the images\n",
        "images = glob(\"/train_1/*.jpg\")\n",
        "train_image = []\n",
        "train_class = []\n",
        "for i in tqdm(range(len(images))):\n",
        "   \n",
        "    # creating the image name\n",
        "    train_image.append(images[i].split('/')[2])\n",
        "  \n",
        "    # creating the class of image\n",
        "    train_class.append(images[i].split('/')[2].split('_')[1])\n",
        "    \n",
        "# storing the images and their class in a dataframe\n",
        "train_data = pd.DataFrame()\n",
        "train_data['image'] = train_image\n",
        "train_data['class'] = train_class\n",
        "\n",
        "# converting the dataframe into csv file \n",
        "train_data.to_csv('/content/train_new.csv',header=True, index=False)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 73844/73844 [00:00<00:00, 685421.57it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcCZy-s_LbnT"
      },
      "source": [
        "Reading all the video frames"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJYPiA4pLXea"
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.layers import Dense, InputLayer, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "4p3XsoBqLe68",
        "outputId": "1be94643-13a9-4690-c321-23d77e093c11"
      },
      "source": [
        "train = pd.read_csv('/content/train_new.csv')\n",
        "train.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>v_SkateBoarding_g15_c06.avi_frame3.jpg</td>\n",
              "      <td>SkateBoarding</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>v_Billiards_g13_c06.avi_frame4.jpg</td>\n",
              "      <td>Billiards</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>v_ApplyLipstick_g10_c04.avi_frame3.jpg</td>\n",
              "      <td>ApplyLipstick</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>v_Skiing_g14_c04.avi_frame6.jpg</td>\n",
              "      <td>Skiing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>v_WritingOnBoard_g20_c03.avi_frame5.jpg</td>\n",
              "      <td>WritingOnBoard</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     image           class\n",
              "0   v_SkateBoarding_g15_c06.avi_frame3.jpg   SkateBoarding\n",
              "1       v_Billiards_g13_c06.avi_frame4.jpg       Billiards\n",
              "2   v_ApplyLipstick_g10_c04.avi_frame3.jpg   ApplyLipstick\n",
              "3          v_Skiing_g14_c04.avi_frame6.jpg          Skiing\n",
              "4  v_WritingOnBoard_g20_c03.avi_frame5.jpg  WritingOnBoard"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCYeV6aZLfQS",
        "outputId": "fc5a61a2-83f2-48a0-d79f-ffd27d51bcfe"
      },
      "source": [
        "# creating an empty list\n",
        "train_image = []\n",
        "\n",
        "# for loop to read and store frames\n",
        "for i in tqdm(range(1500)):\n",
        "  \n",
        "    # loading the image and keeping the target size as (224,224,3)\n",
        "    img = image.load_img('/train_1/'+train['image'][i], target_size=(224,224,3))\n",
        "    # converting it to array\n",
        "    img = image.img_to_array(img)\n",
        "    # normalizing the pixel value\n",
        "    img = img/255\n",
        "    # appending the image to the train_image list\n",
        "    train_image.append(img)\n",
        "    \n",
        "# converting the list to numpy array\n",
        "X = np.array(train_image)\n",
        "\n",
        "# shape of the array\n",
        "X.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1500/1500 [00:02<00:00, 502.22it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1500, 224, 224, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZyc7xQkvVz0"
      },
      "source": [
        "Was supposed to have a sample size of 73844, but my ram couldn't hold even 30 % of that and I still need a lot of it for future operations so I'll only do 900 samples. We're only testing whether we can actually put a model onto a website that inputs videos anyway so it shouldn't matter how correct our model is right now."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8Hjg9xMMfWF"
      },
      "source": [
        "Expected Output: (73844, 224, 224, 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6COuapDjLlE3"
      },
      "source": [
        "Creating a validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W74fPhQnLiRw"
      },
      "source": [
        "# separating the target\n",
        "y = train['class']\n",
        "y = y[:1500]\n",
        "\n",
        "\n",
        "# creating the training and validation set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2, stratify = y)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6ZcVkgoLsma"
      },
      "source": [
        "# creating dummies of target variable for train and validation set\n",
        "y_train = pd.get_dummies(y_train)\n",
        "y_test = pd.get_dummies(y_test)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMlMkn2qLvEK"
      },
      "source": [
        "Defining the architecture of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPkHhnx6LxK-",
        "outputId": "8e7f40f1-a37f-484c-e6a4-99643fa138cf"
      },
      "source": [
        "# creating the base model of pre-trained VGG16 model\n",
        "base_model = VGG16(weights='imagenet', include_top=False)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdVex8rHLxiP",
        "outputId": "927b8c65-df43-42e5-b9da-9c5949c74f00"
      },
      "source": [
        "# extracting features for training frames\n",
        "X_train = base_model.predict(X_train)\n",
        "X_train.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1200, 7, 7, 512)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfB8CVwc4vVl"
      },
      "source": [
        "Output is different since sample size was reduced"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZqpIgeeMtDT"
      },
      "source": [
        "Expected Output: (59075, 7, 7, 512)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhTgYLbrL0Od",
        "outputId": "999213b0-208a-4737-95b9-7442aa920535"
      },
      "source": [
        "# extracting features for validation frames\n",
        "X_test = base_model.predict(X_test)\n",
        "X_test.shape"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300, 7, 7, 512)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4cNrjzK45R6"
      },
      "source": [
        "Output is different since sample size was reduced"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81p9N8AqMz9r"
      },
      "source": [
        "Expected Output: (14769, 7, 7, 512)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uiDRJ-ZL2YR"
      },
      "source": [
        "# reshaping the training as well as validation frames in single dimension\n",
        "X_train = X_train.reshape(1200, 7*7*512)\n",
        "X_test = X_test.reshape(300, 7*7*512)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUGTRXZzL4ho"
      },
      "source": [
        "# normalizing the pixel values\n",
        "max = X_train.max()\n",
        "X_train = X_train/max\n",
        "X_test = X_test/max"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWXX8tKPL6RX",
        "outputId": "fd8de9f8-d908-4147-cbcc-70fc63e1bad3"
      },
      "source": [
        "# shape of images\n",
        "X_train.shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1200, 25088)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbrdrQryM2VA"
      },
      "source": [
        "Expected Output: (59075, 25088)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkgja2VBL_8N"
      },
      "source": [
        "#defining the model architecture\n",
        "model = Sequential()\n",
        "model.add(Dense(1024, activation='relu', input_shape=(25088,)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(101, activation='softmax'))"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnsGp8v2M-6m"
      },
      "source": [
        "Training the video classification model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "602jN7f-Magq"
      },
      "source": [
        "# defining a function to save the weights of best model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "mcp_save = ModelCheckpoint('weight.hdf5', save_best_only=True, monitor='val_loss', mode='min')"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AWePd5fQxKV"
      },
      "source": [
        "# compiling the model\n",
        "model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqADN5aLNDKa",
        "outputId": "b96dd7a2-0a8d-4f42-e7b1-00bdb5fda9b2"
      },
      "source": [
        "# training the model\n",
        "model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test), callbacks=[mcp_save], batch_size=128)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 4.3861 - accuracy: 0.0400 - val_loss: 4.3279 - val_accuracy: 0.0333\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 4.3414 - accuracy: 0.0408 - val_loss: 4.2882 - val_accuracy: 0.0433\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 4.3084 - accuracy: 0.0367 - val_loss: 4.2579 - val_accuracy: 0.0633\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 4.2559 - accuracy: 0.0517 - val_loss: 4.2293 - val_accuracy: 0.0733\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 4.2392 - accuracy: 0.0558 - val_loss: 4.1924 - val_accuracy: 0.0933\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 4.1968 - accuracy: 0.0550 - val_loss: 4.1594 - val_accuracy: 0.1100\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 4.1464 - accuracy: 0.0717 - val_loss: 4.0591 - val_accuracy: 0.1267\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 4.0710 - accuracy: 0.0792 - val_loss: 3.9847 - val_accuracy: 0.1333\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 4.0076 - accuracy: 0.0817 - val_loss: 3.9420 - val_accuracy: 0.1333\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 3.9492 - accuracy: 0.0992 - val_loss: 3.8822 - val_accuracy: 0.1333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f70b05ad710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krn09Lkf-ia1",
        "outputId": "6178c853-656f-47ca-c810-24059fff13ca"
      },
      "source": [
        "model.save('/content/model1')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/model1/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COpg1zFM_hiS"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BteLn-us_WUl"
      },
      "source": [
        "new_model = tf.keras.models.load_model('/content/model1')"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8iwtIZg_tGj",
        "outputId": "517b3b0e-ae55-48d7-d524-639c8d7cb02a"
      },
      "source": [
        "new_model.summary()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 1024)              25691136  \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 101)               13029     \n",
            "=================================================================\n",
            "Total params: 26,393,189\n",
            "Trainable params: 26,393,189\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "id": "jMtxGHt6_0Ps",
        "outputId": "84dc4c67-e9a6-49ef-8cc2-de97ca48bd83"
      },
      "source": [
        "new_model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test), callbacks=[mcp_save], batch_size=128)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "10/10 [==============================] - 1s 43ms/step - loss: 3.9076 - accuracy: 0.1133 - val_loss: 3.8739 - val_accuracy: 0.1600\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 3.8103 - accuracy: 0.1167 - val_loss: 3.7619 - val_accuracy: 0.1400\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 0s 19ms/step - loss: 3.7715 - accuracy: 0.1108 - val_loss: 3.7063 - val_accuracy: 0.1567\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 0s 18ms/step - loss: 3.7056 - accuracy: 0.1242 - val_loss: 3.6569 - val_accuracy: 0.1700\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 3.6602 - accuracy: 0.1250 - val_loss: 3.6284 - val_accuracy: 0.1800\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-19acd4d4c036>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmcp_save\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1143\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1145\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1146\u001b[0m         \u001b[0mtraining_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_supports_tf_logs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_freq\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'epoch'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1344\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_should_save_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_save_model\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m   1394\u001b[0m                     filepath, overwrite=True, options=self._options)\n\u001b[1;32m   1395\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1396\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1397\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1398\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m   2000\u001b[0m     \u001b[0;31m# pylint: enable=line-too-long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2001\u001b[0m     save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n\u001b[0;32m-> 2002\u001b[0;31m                     signatures, options, save_traces)\n\u001b[0m\u001b[1;32m   2003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2004\u001b[0m   def save_weights(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m    152\u001b[0m           'or using `save_weights`.')\n\u001b[1;32m    153\u001b[0m     hdf5_format.save_model_to_hdf5(\n\u001b[0;32m--> 154\u001b[0;31m         model, filepath, overwrite, include_optimizer)\n\u001b[0m\u001b[1;32m    155\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     saved_model_save.save(model, filepath, overwrite, include_optimizer,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36msave_model_to_hdf5\u001b[0;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m    129\u001b[0m     if (include_optimizer and model.optimizer and\n\u001b[1;32m    130\u001b[0m         not isinstance(model.optimizer, optimizer_v1.TFOptimizer)):\n\u001b[0;32m--> 131\u001b[0;31m       \u001b[0msave_optimizer_weights_to_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36msave_optimizer_weights_to_hdf5_group\u001b[0;34m(hdf5_group, optimizer)\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0mparam_dset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m         \u001b[0mparam_dset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/h5py/_hl/dataset.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, args, val)\u001b[0m\n\u001b[1;32m    706\u001b[0m         \u001b[0mmspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_simple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmshape_pad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh5s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNLIMITED\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmshape_pad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfspace\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mselection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdxpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dxpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread_direct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_sel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest_sel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Le56ZJAKAQsM"
      },
      "source": [
        "from google.colab import files"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wWCTiW4A2Hi",
        "outputId": "61b141d7-c883-41b6-dc62-04172af138a6"
      },
      "source": [
        "!zip -r /content/model_video_trained.zip /content/model1"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: content/model1/ (stored 0%)\n",
            "  adding: content/model1/saved_model.pb (deflated 89%)\n",
            "  adding: content/model1/variables/ (stored 0%)\n",
            "  adding: content/model1/variables/variables.index (deflated 66%)\n",
            "  adding: content/model1/variables/variables.data-00000-of-00001 (deflated 16%)\n",
            "  adding: content/model1/assets/ (stored 0%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "HtVE4JfGA-kq",
        "outputId": "b704942c-53bc-45b9-b241-89c36457fd68"
      },
      "source": [
        "files.download('/content/model_video_trained.zip')"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_a7bccef0-711b-4cd1-abf9-adcbb68a43a3\", \"model_video_trained.zip\", 267308056)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}